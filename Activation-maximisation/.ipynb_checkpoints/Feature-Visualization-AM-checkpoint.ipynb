{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44063536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PytorchRevelio import PytorchRevelio\n",
    "from utilities_PytorchRevelio import imagenet_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1702dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load the model from parent directory\n",
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath('../neural networks/Shapes'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894f9920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = models.resnet18(pretrained=True)\n",
    "print(model)\n",
    "'''\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"..\"))))\n",
    "# importing\n",
    "from CNNmodel import ConvNet\n",
    "\n",
    "# load model\n",
    "model = ConvNet()\n",
    "model.load_state_dict(torch.load(\"..\\\\square_classifier\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff80998a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc): Linear(in_features=320000, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ddd4a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "++++++++++\n",
      "\n",
      "----------\n",
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (conv3): Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (fc): Linear(in_features=320000, out_features=2, bias=True)\n",
      ")\n",
      "++++++++++\n",
      "conv1\n",
      "----------\n",
      "Conv2d(1, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "++++++++++\n",
      "bn1\n",
      "----------\n",
      "BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "++++++++++\n",
      "relu1\n",
      "----------\n",
      "ReLU()\n",
      "++++++++++\n",
      "pool\n",
      "----------\n",
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "++++++++++\n",
      "conv2\n",
      "----------\n",
      "Conv2d(12, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "++++++++++\n",
      "relu2\n",
      "----------\n",
      "ReLU()\n",
      "++++++++++\n",
      "conv3\n",
      "----------\n",
      "Conv2d(20, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "++++++++++\n",
      "bn3\n",
      "----------\n",
      "BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "++++++++++\n",
      "relu3\n",
      "----------\n",
      "ReLU()\n",
      "++++++++++\n",
      "fc\n",
      "----------\n",
      "Linear(in_features=320000, out_features=2, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# choose GPU if it is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: {}'.format(device))\n",
    "\n",
    "# put network on device\n",
    "model.to(device)\n",
    "\n",
    "# print name of modules\n",
    "for key, value in PytorchRevelio.layers_name_type(model):\n",
    "    print('+' * 10)\n",
    "    print(key)\n",
    "    print('-' * 10)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7bceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network transformer for input image\n",
    "'''\n",
    "img_transformer = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "'''\n",
    "\n",
    "img_transformer = transforms.Compose([\n",
    "    transforms.Resize((200,200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=0., std=1.),\n",
    "    transforms.Grayscale()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16321f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sashe\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing of layer conv1, filter/neuron 6 is done.\n",
      "Processing of layer conv1, filter/neuron 0 is done.\n",
      "Processing of layer conv1, filter/neuron 3 is done.\n",
      "Processing of layer conv1, filter/neuron 4 is done.\n",
      "Processing of layer conv1, filter/neuron 1 is done.\n",
      "Processing of layer conv1, filter/neuron 3 is done.\n",
      "Processing of layer conv1, filter/neuron 10 is done.\n",
      "Processing of layer conv1, filter/neuron 9 is done.\n",
      "Processing of layer conv2, filter/neuron 16 is done.\n",
      "Processing of layer conv2, filter/neuron 19 is done.\n",
      "Processing of layer conv2, filter/neuron 11 is done.\n",
      "Processing of layer conv2, filter/neuron 19 is done.\n",
      "Processing of layer conv2, filter/neuron 2 is done.\n",
      "Processing of layer conv2, filter/neuron 16 is done.\n",
      "Processing of layer conv2, filter/neuron 17 is done.\n",
      "Processing of layer conv2, filter/neuron 16 is done.\n",
      "Processing of layer conv3, filter/neuron 16 is done.\n",
      "Processing of layer conv3, filter/neuron 31 is done.\n",
      "Processing of layer conv3, filter/neuron 5 is done.\n",
      "Processing of layer conv3, filter/neuron 18 is done.\n",
      "Processing of layer conv3, filter/neuron 28 is done.\n",
      "Processing of layer conv3, filter/neuron 13 is done.\n",
      "Processing of layer conv3, filter/neuron 18 is done.\n",
      "Processing of layer conv3, filter/neuron 28 is done.\n",
      "Processing of layer fc, filter/neuron 1 is done.\n",
      "Processing of layer fc, filter/neuron 0 is done.\n",
      "Processing of layer fc, filter/neuron 1 is done.\n"
     ]
    }
   ],
   "source": [
    "# for different convolutional filter and neuron in fully connected layer\n",
    "# show representation\n",
    "first_layer_name = 'conv1'\n",
    "last_layer_name = 'conv3'\n",
    "for layer_name in model.named_modules():\n",
    "\n",
    "    layer_name = layer_name[0]\n",
    "\n",
    "    # select convolutional and fully connected layers for visualization\n",
    "    layer = PytorchRevelio.return_module_by_name(network=model, module_name=layer_name)\n",
    "\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        filter_neuron_num = layer.out_channels\n",
    "        layer_type = 'Conv2d'\n",
    "        num_iter = 150\n",
    "        lr = 1\n",
    "    elif isinstance(layer, nn.Linear):\n",
    "        filter_neuron_num = layer.out_features\n",
    "        layer_type = 'Linear'\n",
    "        num_iter = 500\n",
    "        lr = 1\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    # from each layer select 8 filter our neurons\n",
    "    filters_neuron_indexs = np.random.choice([i for i in range(filter_neuron_num)], size=8)\n",
    "\n",
    "    # for each selected filter or neuron, calculate representation\n",
    "    plt.figure()\n",
    "    for i, filter_neuron_index in enumerate(filters_neuron_indexs):\n",
    "        img = PytorchRevelio.activation_maximization(network=model, img_transformer=img_transformer,\n",
    "                                                     in_img_size=(200, 200, 1),\n",
    "                                                     first_layer_name=first_layer_name, layer_name=layer_name,\n",
    "                                                     filter_or_neuron_index=filter_neuron_index, num_iter=num_iter,\n",
    "                                                     lr=lr, device=device)\n",
    "\n",
    "        # to cpu and normalize for illustration purpose\n",
    "        img = PytorchRevelio.tensor_outputs_to_image(img)\n",
    "\n",
    "        # Illustrate\n",
    "        ax = plt.subplot(2, 4, i+1)\n",
    "        plt.imshow(img)\n",
    "        if layer_name != last_layer_name:\n",
    "            ax.set_title(\"{}\".format(filter_neuron_index))\n",
    "        else:\n",
    "            ax.set_title(\"{}, {}\".format(filter_neuron_index, imagenet_labels(class_number=filter_neuron_index)))\n",
    "\n",
    "        plt.suptitle('Layer Name: {}, Type: {}'.format(layer_name, layer_type))\n",
    "        ax.axis('off')\n",
    "        print('Processing of layer {}, filter/neuron {} is done.'.format(layer_name, filter_neuron_index))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60dce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
